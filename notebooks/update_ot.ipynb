{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "\n",
    "import ott\n",
    "from ott.geometry import pointcloud\n",
    "from ott.problems.linear import linear_problem\n",
    "from ott.solvers.linear import sinkhorn\n",
    "from ott.tools import plot, sinkhorn_divergence\n",
    "from ott.tools.sinkhorn_divergence import SinkhornDivergenceOutput\n",
    "from ott.solvers.linear import implicit_differentiation as imp_diff\n",
    "import equinox as eqx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def sink_div(combined, states, y, b, key) -> tuple[float, float]:\n",
    "    # y - intentions of expert\n",
    "    agent_value, agent_policy = combined\n",
    "    z_dist = eqx.filter_vmap(agent_policy)(states)\n",
    "    z, log_prob = z_dist.sample_and_log_prob(seed=key) # intentions of agent\n",
    "\n",
    "    geom = pointcloud.PointCloud(z, y, epsilon=0.001)\n",
    "    \n",
    "    a = eqx.filter_vmap(agent_value)(states, z).squeeze() # weights for intents of agent\n",
    "    an = jax.nn.softplus(a - jnp.quantile(a, 0.01)) \n",
    "    bn = jax.nn.softplus(b - jnp.quantile(b, 0.01))\n",
    "        \n",
    "\n",
    "    an = an / an.sum()\n",
    "    bn = bn / bn.sum()\n",
    "    ot = sinkhorn_divergence.sinkhorn_divergence(\n",
    "        geom,\n",
    "        x=geom.x,\n",
    "        a=an,\n",
    "        b=bn,\n",
    "        y=geom.y,\n",
    "        static_b=True,\n",
    "        sinkhorn_kwargs={\n",
    "            \"implicit_diff\": imp_diff.ImplicitDiff(),\n",
    "            \"use_danskin\": True,\n",
    "            \"threshold\": 1e-4,\n",
    "            \"max_iterations\": 2000\n",
    "        },\n",
    "    )\n",
    "    return ot.divergence, (-log_prob.squeeze()).min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import equinox as eqx\n",
    "import equinox.nn as eqxnn\n",
    "\n",
    "class MonolithicVF_EQX(eqx.Module):\n",
    "    net: eqx.Module\n",
    "    \n",
    "    def __init__(self, key, state_dim, intents_dim, hidden_dims):\n",
    "        key, mlp_key = jax.random.split(key, 2)\n",
    "        self.net = eqxnn.MLP(\n",
    "            in_size=state_dim + intents_dim, out_size=1, width_size=hidden_dims[-1], depth=len(hidden_dims), key=mlp_key\n",
    "        )\n",
    "        \n",
    "    def __call__(self, observations, intents):\n",
    "        # TODO: Maybe try FiLM conditioning like in SAC-RND?\n",
    "        conditioning = jnp.concatenate([observations, intents], axis=-1)\n",
    "        return self.net(conditioning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "import distrax\n",
    "from jax import Array\n",
    "from jaxtyping import PyTree\n",
    "\n",
    "\n",
    "class FixedDistrax(eqx.Module):\n",
    "    cls: type\n",
    "    args: PyTree[Any]\n",
    "    kwargs: PyTree[Any]\n",
    "\n",
    "    def __init__(self, cls, *args, **kwargs):\n",
    "        self.cls = cls\n",
    "        self.args = args\n",
    "        self.kwargs = kwargs\n",
    "\n",
    "    def sample_and_log_prob(self, *, seed):\n",
    "        return self.cls(*self.args, **self.kwargs).sample_and_log_prob(seed=seed)\n",
    "\n",
    "    def sample(self, *, seed):\n",
    "        return self.cls(*self.args, **self.kwargs).sample(seed=seed)\n",
    "\n",
    "    def log_prob(self, x):\n",
    "        return self.cls(*self.args, **self.kwargs).log_prob(x)\n",
    "\n",
    "    def mean(self):\n",
    "        return self.cls(*self.args, **self.kwargs).mean()\n",
    "\n",
    "\n",
    "\n",
    "class ND(eqx.Module):\n",
    "\n",
    "    loc: jax.Array\n",
    "    scale_diag: jax.Array\n",
    "    \n",
    "    def __init__(self, loc, scale_diag):\n",
    "        self.loc = loc\n",
    "        self.scale_diag = scale_diag\n",
    "        \n",
    "    def sample_and_log_prob(self, seed):\n",
    "        s = self.sample(seed)\n",
    "        return s, self.log_prob(s)\n",
    "\n",
    "    def sample(self, seed):\n",
    "        loc = self.loc\n",
    "        e = jax.random.normal(seed, loc.shape)\n",
    "        return loc + self.scale_diag * e \n",
    "\n",
    "    def log_prob(self, x):\n",
    "        return jax.scipy.stats.norm.logpdf(x, self.loc, self.scale_diag).sum(-1)\n",
    "\n",
    "\n",
    "\n",
    "class GaussianIntentPolicy(eqx.Module):\n",
    "    net: eqx.Module\n",
    "    \n",
    "    log_std_min: int = -5.0\n",
    "    log_std_max: int = 2.0\n",
    "    temperature: float = 10.0\n",
    "    \n",
    "    def __init__(self, key, state_dim, intent_dim, hidden_dims):\n",
    "        key, key_means, key_log_std = jax.random.split(key, 3)\n",
    "        \n",
    "        self.net = eqx.nn.MLP(in_size=state_dim,\n",
    "                              out_size=2 * intent_dim,\n",
    "                              width_size=hidden_dims[0],\n",
    "                              depth=len(hidden_dims),\n",
    "                              key=key_means)\n",
    "        \n",
    "    def __call__(self, state):\n",
    "        means, log_std = jnp.split(self.net(state), 2)\n",
    "        log_stds = jnp.clip(log_std, self.log_std_min, self.log_std_max)\n",
    "        # dist = FixedDistrax(distrax.MultivariateNormalDiag, loc=means,\n",
    "        #                     scale_diag=jnp.exp(log_stds)) #ND(loc=means, scale_diag=jnp.exp(log_stds))\n",
    "        dist = ND(loc=means, scale_diag=jnp.exp(log_stds))\n",
    "        return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-10 23:24:40.515521: W external/xla/xla/service/gpu/buffer_comparator.cc:1054] INTERNAL: ptxas exited with non-zero error code 65280, output: ptxas /tmp/tempfile-bio-dna-20106e7d-5766-609d21c28e80d, line 10; fatal   : Unsupported .version 7.8; current version is '7.7'\n",
      "ptxas fatal   : Ptx assembly aborted due to errors\n",
      "\n",
      "Relying on driver to perform ptx compilation. \n",
      "Setting XLA_FLAGS=--xla_gpu_cuda_data_dir=/path/to/cuda  or modifying $PATH can be used to set the location of ptxas\n",
      "This message will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250,)\n"
     ]
    }
   ],
   "source": [
    "key = jax.random.PRNGKey(1)\n",
    "model = GaussianIntentPolicy(key=key,\n",
    "                             hidden_dims=[64, 64, 64],\n",
    "                             state_dim=2,\n",
    "                             intent_dim=2)\n",
    "\n",
    "x = 0.25 * jax.random.normal(key, (250, 2)) \n",
    "z_dist = eqx.filter_vmap(model)(x)\n",
    "z, log_prob = z_dist.sample_and_log_prob(seed=key)\n",
    "\n",
    "print(log_prob.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optax\n",
    "import dataclasses\n",
    "\n",
    "class TrainStateEQX(eqx.Module):\n",
    "    model: eqx.Module\n",
    "    optim: optax.GradientTransformation\n",
    "    optim_state: optax.OptState\n",
    "\n",
    "    @classmethod\n",
    "    def create(cls, *, model, optim, **kwargs):\n",
    "        optim_state = optim.init(eqx.filter(model, eqx.is_array))\n",
    "        return cls(model=model, optim=optim, optim_state=optim_state,\n",
    "                   **kwargs)\n",
    "    \n",
    "    @eqx.filter_jit\n",
    "    def apply_updates(self, grads):\n",
    "        updates, new_optim_state = self.optim.update(grads, self.optim_state, self.model)\n",
    "        new_model = eqx.apply_updates(self.model, updates)\n",
    "        return dataclasses.replace(\n",
    "            self,\n",
    "            model=new_model,\n",
    "            optim_state=new_optim_state\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def gradient_flow(\n",
    "    x: jnp.ndarray,\n",
    "    y: jnp.ndarray,\n",
    "    b,\n",
    "    cost_fn: callable,\n",
    "    num_iter: int = 6000,\n",
    "    dump_every: int = 50\n",
    "):\n",
    "    \"\"\"Compute a gradient flow.\"\"\"\n",
    "\n",
    "    def v_loss(agent_policy, agent_value, states, key) -> float:\n",
    "        z_dist = eqx.filter_vmap(agent_policy)(states)\n",
    "        z, _ = z_dist.sample_and_log_prob(seed=key)\n",
    "        v = eqx.filter_vmap(agent_value)(states, z).squeeze()\n",
    "        return -v.mean() * 0.1\n",
    "\n",
    "    cost_fn_vg = eqx.filter_jit(eqx.filter_value_and_grad(cost_fn, has_aux=True))\n",
    "    v_loss_vg = eqx.filter_jit(eqx.filter_value_and_grad(v_loss, has_aux=False))\n",
    "\n",
    "    key = jax.random.PRNGKey(42)\n",
    "    V = TrainStateEQX.create(\n",
    "        model=MonolithicVF_EQX(key, 2, 2, [128, 128, 128]),\n",
    "        optim=optax.adam(learning_rate=3e-4)\n",
    "    )\n",
    "\n",
    "    key, pkey = jax.random.split(key, 2)\n",
    "\n",
    "    policy = TrainStateEQX.create(\n",
    "        model=GaussianIntentPolicy(key=pkey,\n",
    "                             hidden_dims=[128, 128, 128],\n",
    "                             state_dim=2,\n",
    "                             intent_dim=2),\n",
    "        optim=optax.adam(learning_rate=3e-4)\n",
    "    )\n",
    "    for i in range(0, num_iter + 1):\n",
    "        key, key_6 = jax.random.split(key, 2)\n",
    "\n",
    "        (cost, pmin), (value_grads, policy_grads) = cost_fn_vg((V.model, policy.model), x, y, b, key_6)\n",
    "        v_loss, policy_grads_2 = v_loss_vg(policy.model, V.model, x, key_6)\n",
    "       \n",
    "        V = V.apply_updates(value_grads)\n",
    "        policy_grads = jax.tree_map(lambda g1, g2: g1 + g2, policy_grads, policy_grads_2)\n",
    "        policy = policy.apply_updates(policy_grads)\n",
    "\n",
    "        if i % dump_every == 0:\n",
    "            z = eqx.filter_vmap(policy.model)(x).sample(seed=key_6)\n",
    "            a = eqx.filter_vmap(V.model)(x, z).squeeze()\n",
    "            \n",
    "            an = jax.nn.softplus(a - jnp.quantile(a, 0.01))\n",
    "            bn = jax.nn.softplus(b - jnp.quantile(b, 0.01))\n",
    "            an = an / an.sum()\n",
    "            bn = bn / bn.sum()\n",
    "\n",
    "            geom = pointcloud.PointCloud(z, y, epsilon=0.001)\n",
    "            diff = sinkhorn.Sinkhorn()(linear_problem.LinearProblem(geom, a = an, b = bn)).reg_ot_cost\n",
    "            # print(a.min(), a.mean(), a.max())\n",
    "            # print(an.min(), an.mean(), an.max())\n",
    "            print(cost, diff, pmin)\n",
    "            print()\n",
    "\n",
    "    return policy.model, V.model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.074768 1.8227637 1.7290224\n",
      "\n",
      "0.107341364 0.038548037 0.5317926\n",
      "\n",
      "0.10932518 0.050748993 0.26898557\n",
      "\n",
      "0.10725307 0.048360553 0.21133506\n",
      "\n",
      "0.11491291 0.050901167 0.252268\n",
      "\n",
      "0.10030399 0.038433574 0.11526367\n",
      "\n",
      "0.10839401 0.04057438 0.2886464\n",
      "\n",
      "0.10331808 0.033942413 0.34556502\n",
      "\n",
      "0.10312855 0.042218458 0.28834325\n",
      "\n",
      "0.10705197 0.040992375 0.29649103\n",
      "\n",
      "0.09709285 0.033289075 0.36462563\n",
      "\n",
      "0.109361514 0.046177126 0.27830768\n",
      "\n",
      "0.105315395 0.039995104 0.3126964\n",
      "\n",
      "0.110388905 0.045361415 0.29012984\n",
      "\n",
      "0.11780122 0.05492336 0.34669518\n",
      "\n",
      "0.101461306 0.037622146 0.3320344\n",
      "\n",
      "0.11104167 0.046675704 0.35370427\n",
      "\n",
      "0.10872314 0.044631526 0.18860152\n",
      "\n",
      "0.10147652 0.03933075 0.20048974\n",
      "\n",
      "0.096749775 0.03376815 0.32717204\n",
      "\n",
      "0.097046405 0.036267973 0.33117652\n",
      "\n",
      "0.112862185 0.04903081 0.28869057\n",
      "\n",
      "0.09960293 0.039875746 0.32367522\n",
      "\n",
      "0.09779629 0.038981725 0.29801893\n",
      "\n",
      "0.10668324 0.044474345 0.30882272\n",
      "\n",
      "0.10430345 0.04366511 0.3388177\n",
      "\n",
      "0.11779995 0.052845545 0.24904889\n",
      "\n",
      "0.110859096 0.04805383 0.28831878\n",
      "\n",
      "0.10110547 0.04256174 0.1514171\n",
      "\n",
      "0.12376687 0.055949442 0.29944426\n",
      "\n",
      "0.10403833 0.04361677 0.20908588\n",
      "\n",
      "0.11572417 0.053234324 0.36152625\n",
      "\n",
      "0.12246038 0.052975725 0.2957486\n",
      "\n",
      "0.10544358 0.03942752 0.2841468\n",
      "\n",
      "0.102445565 0.042069223 0.33996013\n",
      "\n",
      "0.100430176 0.03490523 0.26779532\n",
      "\n",
      "0.09896676 0.036093287 0.31787604\n",
      "\n",
      "0.097639434 0.037086964 0.26917294\n",
      "\n",
      "0.109961696 0.043471448 0.3555897\n",
      "\n",
      "0.103451945 0.03603987 0.27014723\n",
      "\n",
      "0.110196166 0.044286948 0.2961393\n",
      "\n",
      "0.09874297 0.036015984 0.3014142\n",
      "\n",
      "0.09958497 0.035128087 0.29680207\n",
      "\n",
      "0.10035436 0.036483042 -0.003580602\n",
      "\n",
      "0.09777203 0.036655314 0.16126403\n",
      "\n",
      "0.117457494 0.0576665 0.1340475\n",
      "\n",
      "0.09884433 0.035497934 -0.14065641\n",
      "\n",
      "0.103356406 0.038375415 -0.07120286\n",
      "\n",
      "0.09935927 0.039061364 -0.18874577\n",
      "\n",
      "0.10376448 0.03694374 0.08811938\n",
      "\n",
      "0.10484608 0.04345604 -0.21111906\n",
      "\n",
      "0.10060281 0.038067892 -0.20892613\n",
      "\n",
      "0.10558656 0.04367372 -0.27177575\n",
      "\n",
      "0.1121054 0.049750395 -0.05495873\n",
      "\n",
      "0.097568184 0.03771173 -0.52855\n",
      "\n",
      "0.10980553 0.044451937 0.22378573\n",
      "\n",
      "0.10313769 0.04262283 0.17421676\n",
      "\n",
      "0.1261695 0.058630295 -0.07920521\n",
      "\n",
      "0.09775023 0.033782125 -0.23123634\n",
      "\n",
      "0.10361641 0.039982762 -0.27645427\n",
      "\n",
      "0.103054166 0.043234807 -0.5371027\n",
      "\n",
      "0.105637 0.04222035 0.15265518\n",
      "\n",
      "0.10291285 0.03780375 -0.20226349\n",
      "\n",
      "0.10314083 0.043328878 -0.5893874\n",
      "\n",
      "0.10185951 0.03971601 -0.023069754\n",
      "\n",
      "0.10112258 0.039789177 -0.7218714\n",
      "\n",
      "0.098699264 0.037565067 -1.2981862\n",
      "\n",
      "0.110970385 0.04395014 -0.18440095\n",
      "\n",
      "0.10908955 0.04556915 -1.4627419\n",
      "\n",
      "0.11092499 0.045219973 -0.8192777\n",
      "\n",
      "0.097610585 0.03658954 -1.288728\n",
      "\n",
      "0.10531204 0.042345602 -0.83702654\n",
      "\n",
      "0.11331704 0.043844886 -1.5258834\n",
      "\n",
      "0.106451586 0.04592428 -1.652535\n",
      "\n",
      "0.09780742 0.036375947 -1.7719382\n",
      "\n",
      "0.104675375 0.045274384 -1.4652424\n",
      "\n",
      "0.099058405 0.03267052 -1.0796869\n",
      "\n",
      "0.10620102 0.044019647 -2.1033807\n",
      "\n",
      "0.108892515 0.048466057 -2.0944505\n",
      "\n",
      "0.1032742 0.0382957 -2.5522442\n",
      "\n",
      "0.09885662 0.038388573 -2.085083\n",
      "\n",
      "0.10555856 0.044791646 -2.5015981\n",
      "\n",
      "0.1025652 0.041777678 -2.7882252\n",
      "\n",
      "0.096370004 0.03564472 -2.8240302\n",
      "\n",
      "0.099654615 0.037395675 -3.2722468\n",
      "\n",
      "0.097556815 0.03649354 -3.7364855\n",
      "\n",
      "0.09590752 0.035036147 -3.3578832\n",
      "\n",
      "0.09853422 0.037241317 -2.292324\n",
      "\n",
      "0.108321115 0.051154077 -4.197812\n",
      "\n",
      "0.102635264 0.042213127 -2.7782772\n",
      "\n",
      "0.0938466 0.03196924 -2.3673398\n",
      "\n",
      "0.09724456 0.03434195 -3.2214043\n",
      "\n",
      "0.09212086 0.028645795 -4.6637096\n",
      "\n",
      "0.09453587 0.03188107 -4.4468303\n",
      "\n",
      "0.102171 0.038440347 -4.691925\n",
      "\n",
      "0.098123364 0.035720456 -4.114762\n",
      "\n",
      "0.10140358 0.038822297 -4.200008\n",
      "\n",
      "0.101384416 0.043185048 -4.748427\n",
      "\n",
      "0.09640211 0.032649815 -4.6618605\n",
      "\n",
      "0.0987968 0.03789934 -5.0908113\n",
      "\n",
      "0.105280146 0.041479338 -5.086199\n",
      "\n",
      "0.09672815 0.032788184 -4.8985653\n",
      "\n",
      "0.111574136 0.049754336 -4.66315\n",
      "\n",
      "0.09763045 0.033652812 -5.4687743\n",
      "\n",
      "0.096962035 0.0350704 -5.2777553\n",
      "\n",
      "0.098539785 0.034642905 -5.32736\n",
      "\n",
      "0.09567596 0.035990424 -4.629883\n",
      "\n",
      "0.102844715 0.04274486 -5.206315\n",
      "\n",
      "0.091915414 0.028393766 -4.4973865\n",
      "\n",
      "0.10385557 0.044910233 -4.714361\n",
      "\n",
      "0.09446283 0.03156984 -5.098279\n",
      "\n",
      "0.09497803 0.032671247 -5.4134293\n",
      "\n",
      "0.09425478 0.032724243 -5.982072\n",
      "\n",
      "0.12339616 0.05675127 -5.0244017\n",
      "\n",
      "0.092410825 0.030979818 -6.003634\n",
      "\n",
      "0.08879948 0.026924517 -5.3432055\n",
      "\n",
      "0.10769526 0.045226686 -5.3622327\n",
      "\n",
      "0.09749634 0.03444257 -5.6200986\n",
      "\n",
      "0.101879954 0.03811582 -5.2478924\n",
      "\n",
      "0.097696945 0.03493386 -5.7135506\n",
      "\n",
      "0.09034778 0.027886946 -6.380874\n",
      "\n"
     ]
    }
   ],
   "source": [
    "key1, key2 = jax.random.split(jax.random.PRNGKey(0), 2)\n",
    "\n",
    "\n",
    "x = 0.25 * jax.random.normal(key1, (100, 2))  # Source\n",
    "y = 0.5 * jax.random.normal(key2, (400, 2)) + jnp.array((1, 0))  # Target\n",
    "\n",
    "marginal_b = jax.random.normal(key2, shape=(400, ))\n",
    "policy_model, V_model = gradient_flow(x, y, marginal_b, cost_fn=sink_div)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00673795 0.01371963]\n",
      " [0.00673795 0.0124318 ]\n",
      " [0.00673795 0.01049418]\n",
      " [0.00673795 0.01051167]\n",
      " [0.00673795 0.01393469]\n",
      " [0.00673795 0.01329899]\n",
      " [0.00673795 0.01291853]\n",
      " [0.00673795 0.00869805]\n",
      " [0.00673795 0.00673795]\n",
      " [0.00673795 0.01056215]\n",
      " [0.00673795 0.0083251 ]\n",
      " [0.00673795 0.01127638]\n",
      " [0.00673795 0.01374628]\n",
      " [0.00673795 0.01356966]\n",
      " [0.00673795 0.00760112]\n",
      " [0.00673795 0.01076203]\n",
      " [0.00673795 0.01078376]\n",
      " [0.00673795 0.01412819]\n",
      " [0.00673795 0.00723075]\n",
      " [0.00673795 0.0133966 ]\n",
      " [0.00673795 0.01373136]\n",
      " [0.00673795 0.01288247]\n",
      " [0.00673795 0.00968719]\n",
      " [0.00673795 0.00950502]\n",
      " [0.00673795 0.00902373]\n",
      " [0.00673795 0.00707102]\n",
      " [0.00673795 0.01315871]\n",
      " [0.00673795 0.01330595]\n",
      " [0.00673795 0.01290078]\n",
      " [0.00673795 0.01143418]\n",
      " [0.00673795 0.00915954]\n",
      " [0.00673795 0.00976726]\n",
      " [0.00673795 0.01201004]\n",
      " [0.00673795 0.00875782]\n",
      " [0.00673795 0.00891351]\n",
      " [0.00673795 0.01329588]\n",
      " [0.00673795 0.01108508]\n",
      " [0.00673795 0.00944947]\n",
      " [0.00673795 0.01112261]\n",
      " [0.00673795 0.01057859]\n",
      " [0.00673795 0.00981428]\n",
      " [0.00673795 0.01310336]\n",
      " [0.00673795 0.00986268]\n",
      " [0.00673795 0.01351271]\n",
      " [0.00673795 0.00819077]\n",
      " [0.00673795 0.00863519]\n",
      " [0.00673795 0.01050965]\n",
      " [0.00673795 0.00898485]\n",
      " [0.00673795 0.01125891]\n",
      " [0.00673795 0.00983102]\n",
      " [0.00673795 0.00969852]\n",
      " [0.00673795 0.01250977]\n",
      " [0.00673795 0.01197429]\n",
      " [0.00673795 0.01052238]\n",
      " [0.00673795 0.01394286]\n",
      " [0.00673795 0.01345141]\n",
      " [0.00673795 0.00673795]\n",
      " [0.00673795 0.01223434]\n",
      " [0.00673795 0.00747569]\n",
      " [0.00673795 0.01368137]\n",
      " [0.00673795 0.00673795]\n",
      " [0.00673795 0.00673795]\n",
      " [0.00673795 0.00673795]\n",
      " [0.00673795 0.01206655]\n",
      " [0.00673795 0.01261633]\n",
      " [0.00673795 0.01407252]\n",
      " [0.00673795 0.01311031]\n",
      " [0.00673795 0.01388516]\n",
      " [0.00673795 0.00958678]\n",
      " [0.00673795 0.00901904]\n",
      " [0.00673795 0.0114582 ]\n",
      " [0.00673795 0.01393727]\n",
      " [0.00673795 0.012009  ]\n",
      " [0.00673795 0.01099724]\n",
      " [0.00673795 0.01116775]\n",
      " [0.00673795 0.00686164]\n",
      " [0.00673795 0.0134379 ]\n",
      " [0.00673795 0.0127292 ]\n",
      " [0.00673795 0.00898961]\n",
      " [0.00673795 0.01396594]\n",
      " [0.00673795 0.00735463]\n",
      " [0.00673795 0.01338084]\n",
      " [0.00673795 0.01088533]\n",
      " [0.00673795 0.01364894]\n",
      " [0.00673795 0.0135442 ]\n",
      " [0.00673795 0.00945905]\n",
      " [0.00673795 0.00938093]\n",
      " [0.00673795 0.00673795]\n",
      " [0.00673795 0.01402426]\n",
      " [0.00673795 0.01030538]\n",
      " [0.00673795 0.00853848]\n",
      " [0.00673795 0.00673795]\n",
      " [0.00673795 0.00762104]\n",
      " [0.00673795 0.01142293]\n",
      " [0.00673795 0.00948279]\n",
      " [0.00673795 0.0121492 ]\n",
      " [0.00673795 0.01331509]\n",
      " [0.00673795 0.00673795]\n",
      " [0.00673795 0.01409739]\n",
      " [0.00673795 0.01387973]]\n",
      "[[ 9.08249795e-01  4.92821097e-01]\n",
      " [ 1.01839709e+00 -1.00903183e-01]\n",
      " [ 6.20563924e-01 -6.60465360e-02]\n",
      " [ 9.51543987e-01 -3.08929861e-01]\n",
      " [ 1.21840823e+00  5.27525723e-01]\n",
      " [ 1.09520662e+00  1.50253437e-02]\n",
      " [ 7.04038560e-01  2.88056254e-01]\n",
      " [ 1.18462229e+00 -5.47557712e-01]\n",
      " [-2.97288671e-02 -6.20148838e-01]\n",
      " [ 5.87299585e-01  7.26484880e-03]\n",
      " [ 1.18431127e+00 -5.97489715e-01]\n",
      " [ 1.19956613e+00 -2.48130351e-01]\n",
      " [ 1.11780560e+00  7.09128797e-01]\n",
      " [ 1.17706132e+00  4.83474992e-02]\n",
      " [ 1.32709813e+00 -7.16746569e-01]\n",
      " [ 8.16892862e-01 -2.40068644e-01]\n",
      " [ 6.19379938e-01  8.84190798e-01]\n",
      " [ 1.41926217e+00  2.65018582e-01]\n",
      " [ 6.32312775e-01 -5.19098461e-01]\n",
      " [ 8.13925624e-01  5.22524655e-01]\n",
      " [ 1.45188785e+00  1.08613777e+00]\n",
      " [ 1.03939223e+00 -4.85514738e-02]\n",
      " [ 1.59706926e+00 -3.51270944e-01]\n",
      " [ 2.23327947e+00  8.32662046e-01]\n",
      " [ 4.31764394e-01 -2.11668745e-01]\n",
      " [ 1.70548469e-01 -5.53627491e-01]\n",
      " [ 7.93844640e-01  2.35624284e-01]\n",
      " [ 7.99845755e-01  2.63367891e-01]\n",
      " [ 1.62816036e+00  2.01815382e-01]\n",
      " [ 1.23374772e+00 -2.34086663e-01]\n",
      " [ 2.92791516e-01  8.31613243e-01]\n",
      " [ 1.13778448e+00 -4.12061691e-01]\n",
      " [ 1.55614209e+00 -9.90053415e-02]\n",
      " [ 1.71378791e+00 -4.07999188e-01]\n",
      " [ 4.68027681e-01 -3.59006047e-01]\n",
      " [ 1.39383841e+00 -9.76755098e-03]\n",
      " [ 8.27713251e-01 -1.92854807e-01]\n",
      " [ 7.67632306e-01 -4.21009779e-01]\n",
      " [ 1.15591800e+00 -2.62193441e-01]\n",
      " [ 1.84579754e+00 -2.94454731e-02]\n",
      " [ 3.78914386e-01  1.23277396e-01]\n",
      " [ 1.03332007e+00 -7.90186599e-03]\n",
      " [ 1.95935035e+00  3.48797977e-01]\n",
      " [ 1.40506494e+00  3.69326584e-02]\n",
      " [ 1.73467398e+00 -4.74601984e-01]\n",
      " [ 2.92021304e-01  2.28296332e-02]\n",
      " [ 1.86228228e+00  3.12672317e-01]\n",
      " [ 9.50114191e-01 -4.98133630e-01]\n",
      " [ 1.76734567e+00  3.82706150e-03]\n",
      " [ 1.77857471e+00 -2.34043047e-01]\n",
      " [ 3.29496592e-01  1.63546637e-01]\n",
      " [ 1.12830746e+00 -1.14321977e-01]\n",
      " [ 1.21596861e+00 -1.77549154e-01]\n",
      " [ 1.86247373e+00  2.59483121e-02]\n",
      " [ 1.08109117e+00  2.18539357e-01]\n",
      " [ 8.41625869e-01  5.38265765e-01]\n",
      " [ 1.63202643e+00 -8.73361051e-01]\n",
      " [ 6.35023296e-01  2.46098906e-01]\n",
      " [ 1.89324832e+00 -4.96488690e-01]\n",
      " [ 1.18461621e+00  8.59176934e-01]\n",
      " [ 1.14904904e+00 -9.28113580e-01]\n",
      " [ 7.40908623e-01 -5.76300859e-01]\n",
      " [ 3.84438962e-01 -9.05586720e-01]\n",
      " [ 8.82480025e-01 -6.71035498e-02]\n",
      " [ 7.65886486e-01  7.59504497e-01]\n",
      " [ 1.24391758e+00  3.11613232e-01]\n",
      " [ 8.44500721e-01  7.08380580e-01]\n",
      " [ 1.37687516e+00  1.30089775e-01]\n",
      " [ 5.28843462e-01 -1.68225765e-01]\n",
      " [ 4.18565184e-01 -1.25708878e-01]\n",
      " [ 5.82036912e-01  7.38694906e-01]\n",
      " [ 1.03699565e+00  3.73387396e-01]\n",
      " [ 6.90325081e-01  1.43803224e-01]\n",
      " [ 9.81810510e-01 -2.62209058e-01]\n",
      " [ 1.87162113e+00  4.84754205e-01]\n",
      " [ 1.70619893e+00 -6.93047225e-01]\n",
      " [ 8.82602334e-01  1.86263785e-01]\n",
      " [ 6.07238531e-01  3.64762723e-01]\n",
      " [ 1.29813313e+00 -5.19300222e-01]\n",
      " [ 1.06958866e+00  2.79174596e-01]\n",
      " [ 6.31225929e-02 -1.93667747e-02]\n",
      " [ 1.20683742e+00 -1.16764382e-03]\n",
      " [ 6.84339345e-01 -7.20342398e-02]\n",
      " [ 1.43170953e+00  7.87911415e-02]\n",
      " [ 1.14713407e+00  5.17958812e-02]\n",
      " [ 9.59003389e-01  1.13768685e+00]\n",
      " [ 1.16694129e+00 -4.60957736e-01]\n",
      " [ 5.36771476e-01 -8.89912963e-01]\n",
      " [ 1.39713979e+00  5.84233522e-01]\n",
      " [ 2.92071790e-01  3.11177909e-01]\n",
      " [ 4.85080272e-01 -4.33614463e-01]\n",
      " [ 1.68879771e+00 -8.85034740e-01]\n",
      " [ 1.00387907e+00 -6.82178557e-01]\n",
      " [ 6.91904068e-01  3.32817398e-02]\n",
      " [ 7.11332187e-02  3.89357030e-01]\n",
      " [ 5.03961027e-01  4.03528631e-01]\n",
      " [ 9.49705064e-01  8.62180889e-02]\n",
      " [ 9.94493067e-01 -1.19125664e+00]\n",
      " [ 1.43997669e+00  3.57534230e-01]\n",
      " [ 1.28977942e+00  6.60688460e-01]]\n",
      "-8.064925\n"
     ]
    }
   ],
   "source": [
    "key = jax.random.PRNGKey(0)\n",
    "z_dist = eqx.filter_vmap(policy_model)(x)\n",
    "z, log_prob = z_dist.sample_and_log_prob(seed=key)\n",
    "\n",
    "print(z_dist.scale_diag)\n",
    "print(z_dist.loc)\n",
    "print((-log_prob).min())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
